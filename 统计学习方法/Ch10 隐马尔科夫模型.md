# Ch10 隐马尔科夫模型

HMM 模型是可以用于标注问题的统计学习模型，描述由隐藏马尔科夫随机生成观测序列的过过程，属于生成模型。

<!-- TOC -->

- [1. 隐马尔科夫模型的基本概念](#1-隐马尔科夫模型的基本概念)
    - [1.1. 定义](#11-定义)
    - [1.2. 隐马尔科夫模型的3个基本问题](#12-隐马尔科夫模型的3个基本问题)
- [2. 概率计算算法](#2-概率计算算法)
    - [2.1. 直接计算法](#21-直接计算法)
    - [2.2. 前向算法](#22-前向算法)

<!-- /TOC -->

## 1. 隐马尔科夫模型的基本概念

### 1.1. 定义

> 隐马尔科夫模型是关于时间序列的模型，描述一个隐藏的马尔科夫链随机过程生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。

隐藏的马尔科夫链随机生成的状态的序列称为状态序列，
每个状态生成一个观测，而由此产生的观测的随机序列称为观测序列。

组成：
- 初始概率分布
- 状态转移概率分布
- 观测概率分布

形式定义：

- $Q$ 是所有可能状态集合
- $V$ 是所有的可能观测集合
- $I$ 状态序列
- $O$ 对应的观测序列
- $A$ $_{N\times N}$ 状态转移矩阵
- $B$ $_{N\times M}$ 观测概率矩阵
- $\pi$ 初始状态概率向量

$$
Q = \{q_1,q_2,\dots,q_N\} \quad V = \{v_1, v_2,\dots,v_M\}
$$

$$
\begin{aligned}
a_{ij} &= P(i_{i+1}=q_j|i_t=q_i) \\
b_{jk} &= P(o_t=v_k|i_t=q_j)
\end{aligned}
$$

两个基本假设：

1. 齐次马尔科夫性假设，即假设隐藏的马尔科夫链在任意时刻 $t$ 的状态只依赖于其前一时刻的状态，与其他时刻的状态及观测无关，也与时刻 $t$ 无关

$$
P(i_t|i_{t-1},o_{t-1},\dots,i_1,o_1) = P(i_t|i_{t-1})
$$

2. 观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔科夫状态，与其他观测及状态无关

$$
P(o_t|i_T,o_T,i_{T-1},\dots,i_{t+1},o_{t+1},i_t,i_{t-1},\dots,i_1,o_1) = P(o_t|i_t)
$$

隐马尔科夫模型可以用于标注，这时状态对应着标记。标注问题是给定观测的序列，观测其对应的标记序列。可以假设标注问题的数据是由隐马尔科夫模型生成的，这样我们可以利用隐马尔科夫模型的学习与预测算法进行标注。


### 1.2. 隐马尔科夫模型的3个基本问题


1. 概率计算问题。给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,\dots,o_T)$，计算在模型 $\lambda$ 下的观测序列 $O$ 出现的概率 $P(O|\lambda)$
2. 学习问题。已知观测序列 $O=(o_1,o_2,\dots,o_T)$，估计模型 $\lambda=(A,B,\pi)$ 的参数，使得在该模型下，观测序列概率 $P(O|\lambda)$ 最大。即用极大似然估计的方法估计参数。
3. 预测问题，也称为解码问题。已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,\dots,o_T)$，求对给定观测序列条件概率 $P(I|O)$ 最大的状态序列 $I=(i_1,i_2,\dots,i_T)$。即给定观测序列，求最有可能的对应的状态序列。


## 2. 概率计算算法

### 2.1. 直接计算法

给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,\dots,o_T)$，计算观测序列 $O$ 出现的概率 $P(O|\lambda)$。

概率相乘，计算量大。

### 2.2. 前向算法

前向概率记作：

$$
\alpha_t(i) = P(o_1,o_2,\dots,o_t,i_t=q_i|\lambda)
$$
