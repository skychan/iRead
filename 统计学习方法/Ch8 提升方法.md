# Ch8 提升方法

是一种常见的统计学习方法。在分类问题中，通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类的性能。


## 提升方法 AdaBoost 算法

### 提升方法的基本思路

对于一个复杂问题来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独判断的要好。

概率近似正确（probably approximately correct, PAC）学习框架中，一个强可学习的充分必要条件是弱可学习。这样一来，问题便成为，如果已经发现了“弱学习”算法，如何提升成为“强学习”算法。

提升方法就是从弱学习方法出发，反复学习，得到一系列弱分类器（基本分类器），然后组合这些分类器，构成一个强分类器。

大多数提升方法都是改变训练数据的概率分布（权值）。

**两个问题：**
1. 在每一轮如何改变训练数据的权值分布
2. 如何将弱分类器组合成一个强分类器

AdaBoost 算法：
1. 加大被错误分类的样本权值
2. 加大分类误差率小的分类器权值

### AdaBoost 算法


