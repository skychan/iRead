# Ch7 支持向量机

支持向量机是一种二分类模型，定义在特征空间上的间隔最大的线性分类器。

有区别于感知机，包括一些核技巧，这使他成为实质上的非线性分类器。

学习的策略：间隔最大化，可以形式化为一个求解凸二次规划的问题，等价于正则化的合页损失函数的最小化问题。

其学习算法是求解凸二次规划的最优化算法。

构建方法：
1. 线性可分支持向量机
2. 线性支持向量机
3. 非线性支持向量机

当输入空间为欧式空间或者离散集合、特征空间为希尔伯特空间时，核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。通过使用核函数，可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法称为核技巧。

<!-- TOC -->

- [1. 线性可分支持向量机与硬间隔最大化](#1-线性可分支持向量机与硬间隔最大化)
    - [1.1. 线性可分支持向量机](#11-线性可分支持向量机)
- [2. 非线性支持向量机与核函数](#2-非线性支持向量机与核函数)
    - [2.1. 核技巧](#21-核技巧)

<!-- /TOC -->

## 1. 线性可分支持向量机与硬间隔最大化

### 1.1. 线性可分支持向量机

支持向量机的学习是在特征空间进行的。

一般来说，当训练数据集线性可分，存在无穷个分离超平面可将两类数据正确分开。感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个。线性可分支持向量机利用间隔最大化求最优分离超平面，这时解是唯一的。


## 2. 非线性支持向量机与核函数

### 2.1. 核技巧

首先使用一个变换将原空间的数据映射到新空间，然后在新空间里用线性分类学习方法从训练数据中学习分类模型。

思想：通过一个非线性变换将输入空间对应于一个特征空间，这样，分类问题的学习任务通过在特征空间中求解线性支持向量机就可以完成。

