# 强化学习精要

## 1. 信息论基础

- “熵”：可以形容为“惊喜度”，概率越小的事件惊喜程度越大
- KL 散度，描述两个概率之间的差异的一种方法

$$
KL(p||q) = \sum_x p(x) log\frac{p(x)}{q(x)}
$$

两个分布越接近，KL 三度越小，两个分布越远，KL 散度越大。

## 2. 机器学习基础

- 平方损失函数：最终输出的结果是回归问题的一个连续型变量，看重每一个输出结果，损失梯度和分类有关，会让错误的分类都变得更加平均
- 交叉熵损失函数：最终输出是分类问题的一个离散 One-Hot 向量，只看重正确分类，损失梯度只和正确分类的预测结果有关

## 3. 优化算法

### 3.1. 梯度下降法

函数的梯度方向表示了函数值增长速度最快的方向。

### 3.2. 动量算法
一个已经结束的更新不会立即消失，而是以一定的形式衰减，剩下的能量将在继续优化中发挥作用。

使用了动量后，历史的更新会以衰减的形式不断作用在这个方向上，那么沿着-y+y两个方向的动量就可以相互抵消，而-x方向则会一直加强。

更好地穿越一些平坦的优化区域

**Nesterov 算法** 计算梯度在动量更新后的优化点，而不像动量算法在当前的目标点。

### 3.3. 共轭梯度法

选择优化方向和步长上更加智能。强调每一步优化迭代的质量

### 3.4. 自然梯度法

将每一轮迭代中对参数的更新转变为对模型效果的更新

## 4. Tensorflow 一些用法

Variable 表示方法

```python
# 第一种方法
w1 = tf.Variable(tf.random_uniform([2,4], -1, 1), name='w1')
b1 = tf.Variable(tf.zeros(4, dtype=np.float32), name='b1')
# 第二种方法
w2 = tf.get_variable('w2', shape=[4,1], initializer=contrib.layers.xavier_initializer())
b2 = tf.get_variable('b2', shape=[1], initializer=tf.constant(0))
```

3个核心部分：定义模型、定义目标函数和定义优化方法。

### 4.1. 构建计算图

1. 创建变量的 scope

```python
with tf.name_scope('123'):
    with tf.name_scope('456'):
        with tf.variable_scope('789'):
            a = tf.Variable(1, name='a')
            print(a.name)
            b = tf.get_variable('b', 1)
            print(b.name)

# output
123/456/789/a:0
789/b:0
```

在同一个 scope 内，同样的名字的 name_scope 被声明第二次时，scope 的名字并不会直接被复用出现，而是通过改名的形式创建一个全新的 scope。系统会自动改名。

variable_scope 和 name_scope 是两个有点相互独立的命名体系，name_scope 只通过 Variable 创建的变量有效，而 variable_scpoe 还可以为 get_variable 这个复用的变量的方法服务。

- 两种 scope 形成的命名空间将在 Variable 创建的变量上产生影响
- variable_scope 创建的命名空间将对 get_variable 的变量名产生影响
- 创建 named_scope 时，遇到同名的 scope，系统会自动改名创建一个新的 scope
- 创建 named_scope 时，可以通过将名字设置为 None 抹掉前面设定的所有命名空间的名字

2. 运算操作
在编程的时候，最好为每一个 Op 起名字。

## 5. 辅助工具 Gym 与 Baselines

