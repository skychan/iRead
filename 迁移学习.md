# 迁移学习（深度学习实战 PyTorch）

Transfer Learning

使用相同的资源训练的模型能解决**同一类问题**。通过对一个训练好的模型进行细微调整，就能将其应用到相似的问题中，最后还能取得很好的效果。

此外，对于原始数据较少的问题，我们也能通过采用迁移模型进行有效解决。如果能够选取合适的新学习方法，就会对解决我们所面临的问题有很大的帮助。通过迁移学习，可以节省大量的时间和精力，而且取得到的结果不会太差，就是迁移学习的优点和优势。

简单来说，步骤如下：

```python
model = models.resnet50(pretrained=True)  # pretrained 会下载训练好的模型参数

for param in model.parameters():
    param.requires_grad = False           # 原有的参数不用训练了

model.fc = nn.Linear(2048, 2)             # 修改需要修改的地方

optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-5)
```

其余的训练步骤一致。

## 训练的大致步骤

```python
epoch_n = 5
time_s = time.time()

for epoch in range(epoch_n):
    print(f"Epoch {epoch+1}/{epoch_n}")
    print("-"*10)
    
    for phase in ["train", "valid"]:
        if phase == 'train':
            print("Training...")
            model.train(True)
            dataloader = train_data_loader
            img_datasets = train_data
        else:
            print("Validing...")
            model.eval()
            dataloader = test_data_loader
            img_datasets = test_data
        
        running_loss = 0.0
        running_acc = 0.0
        
        for batch, data in tqdm(enumerate(dataloader, 1), total=len(dataloader)):      # 显示进度
            X, y = data
            X, y = Variable(X.cuda()), Variable(y.cuda())
            y_pred = model(X)
            _, pred = torch.max(y_pred.data, 1)
    
            optimizer.zero_grad()
            batch_loss = loss(y_pred, y)

            if phase == "train":
                batch_loss.backward()
                optimizer.step()
            
            running_loss += batch_loss.data
            running_acc += torch.sum(pred == y.data)
            
            if batch%100 == 0 and phase == "train":
                print(f"Batch {batch}, Train Loss {running_loss/(batch):.4f}, Train Acc {100*running_acc/(64*(batch))}")
        
        epoch_loss = running_loss*64/len(img_datasets)
        epoch_acc = 100*running_acc/(len(img_datasets) + 0.0)
        
        print(f"{phase} Loss {epoch_loss:.4f} Acc {epoch_acc:.4f}")
time_e = time.time()
print(f"Spend {(time_e-time_s)/60:.3f} mins")
```


## 其他的一些小技巧

**图像的变换：**

```python
from torchvision import transforms
transform = transforms.Compose([
    transforms.Resize(224, 224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])
])
```

**图像的读取：**

一般通过 `plt.imshow(img)` 来显示。

1. PIL

```python
from PIL import Image

class myDataset(torch.utils.data.Dataset):
    def __init__(self, prefix, files, transform, img_loader):
        self.imgs = files
        self.transform = transform
        self.loader = img_loader
        self.prefix = prefix
    
    def __len__(self):
        return len(self.imgs)
    
    def __getitem__(self, idx):
        img = self.imgs[idx]
        label = 0 if 'cat' in img else 1
        img = self.loader(f"{self.prefix}/{img}")
        return self.transform(img), label


image_loader = lambda file : Image.open(file).convert('RGB')
```

通过

```python
data_loader = torch.utils.data.DataLoader(datasets, batch_size=64, shuffle=True)
```
可以来读取数据

2. Keras

```python
from keras.preprocessing.image import load_img

IMAGE_SIZE = (224, 224)
img = load_img(name, target_size=IMAGE_SIZE)
```

## 进度

在 notebook 中显示进度：

```python
from tqdm import tqdm_notebook as tqdm
```

## 获得结果

```python
model.eval()
result_resnet = {
    name[0]: torch.max(model(Variable(X_test.cuda())) ,1)[1].data.cpu().numpy() 
    for X_test, name in tqdm(T_dataloader, total=len(T_data))


}

result_df_r = pd.DataFrame.from_dict(result_resnet, orient='index', columns=["label"])
result_df_r['id'] = result_df_r.index.str.split(".").str[0].astype(int)
result_df_r = result_df_r[['id', 'label']]
result_df_r = result_df_r.sort_values(by=["id"])
```

